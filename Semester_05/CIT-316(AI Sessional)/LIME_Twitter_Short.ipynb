{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fd431a",
   "metadata": {},
   "source": [
    "# LIME - Twitter Sentiment Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be2a301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 74682 rows\n",
      "Using 3000 samples\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Negative    1066\n",
      "Positive    1014\n",
      "Neutral      920\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Using 3000 samples\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Negative    1066\n",
      "Positive    1014\n",
      "Neutral      920\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model Accuracy: 58.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.58      0.65      0.62       213\n",
      "     Neutral       0.58      0.49      0.53       184\n",
      "    Positive       0.60      0.60      0.60       203\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.58      0.58      0.58       600\n",
      "weighted avg       0.58      0.58      0.58       600\n",
      "\n",
      "\n",
      "\n",
      "LIME EXPLANATIONS\n",
      "\n",
      "Model Accuracy: 58.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.58      0.65      0.62       213\n",
      "     Neutral       0.58      0.49      0.53       184\n",
      "    Positive       0.60      0.60      0.60       203\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.58      0.58      0.58       600\n",
      "weighted avg       0.58      0.58      0.58       600\n",
      "\n",
      "\n",
      "\n",
      "LIME EXPLANATIONS\n",
      "\n",
      "Example 1:\n",
      "Text: kids liked gta ok til i went to pet a cute cat and the girls choked her to death instead i didnt mea...\n",
      "True: Negative | Predicted: Negative\n",
      "\n",
      "Example 1:\n",
      "Text: kids liked gta ok til i went to pet a cute cat and the girls choked her to death instead i didnt mea...\n",
      "True: Negative | Predicted: Negative\n",
      "\n",
      "Example 6:\n",
      "Text: exactly these companies have all posted about it everyone is posting videos of what happened also he...\n",
      "True: Negative | Predicted: Neutral\n",
      "\n",
      "Example 6:\n",
      "Text: exactly these companies have all posted about it everyone is posting videos of what happened also he...\n",
      "True: Negative | Predicted: Neutral\n",
      "\n",
      "Example 11:\n",
      "Text: according to speedtestnet the average speed of google fiber connection declines by  mbit  s and incr...\n",
      "True: Neutral | Predicted: Negative\n",
      "\n",
      "\n",
      "Model ready!\n",
      "\n",
      "Example 11:\n",
      "Text: according to speedtestnet the average speed of google fiber connection declines by  mbit  s and incr...\n",
      "True: Neutral | Predicted: Negative\n",
      "\n",
      "\n",
      "Model ready!\n"
     ]
    }
   ],
   "source": [
    "# LIME Twitter Sentiment - Single Cell\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# 1) Load and clean data\n",
    "df = pd.read_csv('twitter_training.csv', header=None, \n",
    "                 names=['tweet_id', 'entity', 'sentiment', 'tweet_content'])\n",
    "print(f\"Dataset loaded: {len(df)} rows\")\n",
    "\n",
    "df = df.dropna(subset=['tweet_content', 'sentiment'])\n",
    "df = df[df['sentiment'].isin(['Positive', 'Negative', 'Neutral'])].copy()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['cleaned'] = df['tweet_content'].apply(clean_text)\n",
    "df = df[df['cleaned'].str.len() > 5]\n",
    "\n",
    "# Sample for speed\n",
    "df_sample = df.sample(n=min(3000, len(df)), random_state=42)\n",
    "print(f\"Using {len(df_sample)} samples\")\n",
    "print(f\"Sentiment distribution:\\n{df_sample['sentiment'].value_counts()}\\n\")\n",
    "\n",
    "# 2) Prepare data\n",
    "texts = df_sample['cleaned'].values\n",
    "labels = df_sample['sentiment'].values\n",
    "class_names = sorted(df_sample['sentiment'].unique())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# 3) Train model\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english'),\n",
    "    LogisticRegression(max_iter=500, random_state=42)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4) Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {acc*100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 5) Create LIME explainer\n",
    "print(\"\\n\" )\n",
    "print(\"LIME EXPLANATIONS\")\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# 6) Explain 3 test examples\n",
    "test_indices = [0, 5, 10]\n",
    "for idx in test_indices:\n",
    "    if idx >= len(X_test):\n",
    "        continue\n",
    "    text = X_test[idx]\n",
    "    true_label = y_test[idx]\n",
    "    \n",
    "    exp = explainer.explain_instance(text, model.predict_proba, num_features=8)\n",
    "    pred_label = class_names[exp.predict_proba.argmax()]\n",
    "    \n",
    "    print(f\"\\nExample {idx+1}:\")\n",
    "    print(f\"Text: {text[:100]}...\")\n",
    "    print(f\"True: {true_label} | Predicted: {pred_label}\")\n",
    "    # print(\"Top influential words:\")\n",
    "    # for word, weight in exp.as_list()[:8]:\n",
    "    #     emoji = \"✓\" if weight > 0 else \"✗\"\n",
    "    #     print(f\"  {emoji} {word}: {weight:+.3f}\")\n",
    "\n",
    "# 7) Custom explanation function\n",
    "def explain_custom_text(text):\n",
    "    cleaned = clean_text(text)\n",
    "    exp = explainer.explain_instance(cleaned, model.predict_proba, num_features=10)\n",
    "    pred_class = class_names[exp.predict_proba.argmax()]\n",
    "    prob = exp.predict_proba.max()\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted: {pred_class} (Confidence: {prob*100:.1f}%)\")\n",
    "    # print(\"\\nTop features contributing to prediction:\")\n",
    "    # for word, weight in exp.as_list():\n",
    "    #     emoji = \"✓\" if weight > 0 else \"✗\"\n",
    "    #     print(f\"  {emoji} '{word}': {weight:+.3f}\")\n",
    "    return exp\n",
    "\n",
    "print(\"\\n\" )\n",
    "print(\"Model ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9549d",
   "metadata": {},
   "source": [
    "## Test Own Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2128aba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Text: This product is absolutely amazing! I love it so much.\n",
      "Predicted: Positive (Confidence: 88.6%)\n"
     ]
    }
   ],
   "source": [
    "# Enter your text here\n",
    "my_text = \"This product is absolutely amazing! I love it so much.\"\n",
    "\n",
    "# Get LIME explanation\n",
    "explanation = explain_custom_text(my_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
