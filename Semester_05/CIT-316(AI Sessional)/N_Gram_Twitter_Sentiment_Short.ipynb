{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2e2548",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a79f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 74682 rows\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Negative      22542\n",
      "Positive      20832\n",
      "Neutral       18318\n",
      "Irrelevant    12990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After cleaning: 71440 samples\n",
      "Sentiment counts:\n",
      "sentiment\n",
      "Negative      21610\n",
      "Positive      19787\n",
      "Neutral       17510\n",
      "Irrelevant    12533\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train: 57152, Test: 14288\n",
      "\n",
      "\n",
      "Model Accuracy: 63.46%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.71      0.36      0.48      2507\n",
      "    Negative       0.63      0.79      0.70      4322\n",
      "     Neutral       0.66      0.53      0.59      3502\n",
      "    Positive       0.61      0.73      0.66      3957\n",
      "\n",
      "    accuracy                           0.63     14288\n",
      "   macro avg       0.65      0.60      0.61     14288\n",
      "weighted avg       0.64      0.63      0.62     14288\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 905  653  266  683]\n",
      " [ 110 3412  333  467]\n",
      " [ 145  800 1864  693]\n",
      " [ 114  594  363 2886]]\n",
      "\n",
      "\n",
      "TEST EXAMPLES\n",
      "\n",
      "Text: I love this product! It's amazing and works perfectly.\n",
      "Sentiment: Positive (Confidence: 63.5%)\n",
      "\n",
      "Text: This is terrible. Worst experience ever!\n",
      "Sentiment: Negative (Confidence: 67.5%)\n",
      "\n",
      "Text: It's okay, nothing special.\n",
      "Sentiment: Positive (Confidence: 35.9%)\n",
      "\n",
      "\n",
      "Model ready. Use predict_sentiment(text) for custom input.\n"
     ]
    }
   ],
   "source": [
    "# Twitter Sentiment Analysis - Single Cell\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "\n",
    "# 1) Load dataset (adjust path if needed)\n",
    "# Expected columns: 'tweet_id', 'entity', 'sentiment', 'tweet_content'\n",
    "df = pd.read_csv('twitter_training.csv', header=None, names=['tweet_id', 'entity', 'sentiment', 'tweet_content'])\n",
    "print(f\"Dataset loaded: {len(df)} rows\")\n",
    "print(f\"Sentiment distribution:\\n{df['sentiment'].value_counts()}\\n\")\n",
    "\n",
    "# 2) Clean and filter\n",
    "df = df.dropna(subset=['tweet_content', 'sentiment'])\n",
    "df = df[df['sentiment'].isin(['Positive', 'Negative', 'Neutral', 'Irrelevant'])].copy()\n",
    "\n",
    "# Simple text preprocessing\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # remove mentions\n",
    "    text = re.sub(r'#', '', text)  # remove hashtag symbol\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # keep only letters\n",
    "    return text.strip()\n",
    "\n",
    "df['cleaned'] = df['tweet_content'].apply(clean_text)\n",
    "df = df[df['cleaned'].str.len() > 5]  # filter very short tweets\n",
    "\n",
    "print(f\"After cleaning: {len(df)} samples\")\n",
    "print(f\"Sentiment counts:\\n{df['sentiment'].value_counts()}\\n\")\n",
    "\n",
    "# 3) Prepare features and target\n",
    "X = df['cleaned']\n",
    "y = df['sentiment']\n",
    "\n",
    "# 4) Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# 5) Vectorize using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 6) Train Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# 7) Evaluate\n",
    "y_pred = model.predict(X_test_vec)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Model Accuracy: {acc*100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 8) Prediction helper\n",
    "def predict_sentiment(text):\n",
    "    cleaned = clean_text(text)\n",
    "    vec = vectorizer.transform([cleaned])\n",
    "    pred = model.predict(vec)[0]\n",
    "    proba = model.predict_proba(vec)[0]\n",
    "    return pred, proba\n",
    "\n",
    "# 9) Quick test examples\n",
    "print(\"\\n\")\n",
    "print(\"TEST EXAMPLES\")\n",
    "\n",
    "test1 = \"I love this product! It's amazing and works perfectly.\"\n",
    "pred1, prob1 = predict_sentiment(test1)\n",
    "print(f\"\\nText: {test1}\")\n",
    "print(f\"Sentiment: {pred1} (Confidence: {max(prob1)*100:.1f}%)\")\n",
    "\n",
    "test2 = \"This is terrible. Worst experience ever!\"\n",
    "pred2, prob2 = predict_sentiment(test2)\n",
    "print(f\"\\nText: {test2}\")\n",
    "print(f\"Sentiment: {pred2} (Confidence: {max(prob2)*100:.1f}%)\")\n",
    "\n",
    "test3 = \"It's okay, nothing special.\"\n",
    "pred3, prob3 = predict_sentiment(test3)\n",
    "print(f\"\\nText: {test3}\")\n",
    "print(f\"Sentiment: {pred3} (Confidence: {max(prob3)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Model ready. Use predict_sentiment(text) for custom input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556b990",
   "metadata": {},
   "source": [
    "##  Test Own Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cb9ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT ANALYSIS\n",
      "Input Text:\n",
      "  This is absolutely fantastic! I'm so happy with the results.\n",
      "\n",
      "\n",
      "Predicted Sentiment: Positive\n",
      "Confidence: 71.52%\n",
      "\n",
      "All Class Probabilities:\n",
      "  Irrelevant: 15.27%\n",
      "  Negative: 4.06%\n",
      "  Neutral: 9.16%\n",
      "  Positive: 71.52%\n"
     ]
    }
   ],
   "source": [
    "# Enter your text here and run this cell\n",
    "my_text = \"This is absolutely fantastic! I'm so happy with the results.\"\n",
    "\n",
    "# Get prediction\n",
    "sentiment, probabilities = predict_sentiment(my_text)\n",
    "\n",
    "# Display result\n",
    "print(\"SENTIMENT ANALYSIS\")\n",
    "print(f\"Input Text:\\n  {my_text}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Predicted Sentiment: {sentiment}\")\n",
    "print(f\"Confidence: {max(probabilities)*100:.2f}%\")\n",
    "print(\"\\nAll Class Probabilities:\")\n",
    "for label, prob in zip(model.classes_, probabilities):\n",
    "    print(f\"  {label}: {prob*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
